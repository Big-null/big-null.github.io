(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[335],{3018:function(e,i,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/genAI/lecture-02/lecture-02",function(){return n(2085)}])},2085:function(e,i,n){"use strict";n.r(i),n.d(i,{default:function(){return a},useTOC:function(){return c}});var s=n(5893),r=n(7812),t=n(3642);n(237);var l=n(8925),o={src:"/_next/static/media/chrome_8PinsTCm9B.85af2abc.png",height:580,width:1334,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAADCAMAAACZFr56AAAAHlBMVEXw8+7l1eDg5uv5+fvS4efZy9LN2uLa6sng6Nbb3OJTC4i5AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAH0lEQVR4nAXBhwEAAAjCsAKu/y82gcVTFTiwHSKpW3kDkQBA7UbBtgAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:3},d={src:"/_next/static/media/chrome_a8zKpwL8nX.30f1ef14.png",height:1101,width:743,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAICAMAAAAGL8UJAAAAMFBMVEUIISgSNkITPUoXTFsMKjMjZngXXEwocYNrs7oVTUYJFRcTQjUyg5UnXGpSmqWR2NqQhvFtAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAALUlEQVR4nBXEtxEAIBAEsb03eNN/twwKhNV2kqi3OfjKAM/9lwVoSNCnCUoxPRRJALgpWYcCAAAAAElFTkSuQmCC",blurWidth:5,blurHeight:8};function c(e){let i={code:"code",...(0,l.a)()};return[{value:"Generative Adversarial Networks (GAN)",id:"generative-adversarial-networks-gan",depth:2},{value:"What happens in GAN",id:"what-happens-in-gan",depth:3},{value:"GAN process",id:"gan-process",depth:3},{value:"Forward to 2022 / 2023",id:"forward-to-2022--2023",depth:3},{value:"Latent Space",id:"latent-space",depth:2},{value:"Text to images",id:"text-to-images",depth:2},{value:"MMDiT",id:"mmdit",depth:3},{value:"System Implications of Multi-Modal Generation",id:"system-implications-of-multi-modal-generation",depth:3},{value:"Stable diffusion noise visualization Demo",id:"stable-diffusion-noise-visualization-demo",depth:2},{value:"Terms for Config",id:"terms-for-config",depth:2},{value:"Generation configs",id:"generation-configs",depth:3},{value:(0,s.jsxs)(s.Fragment,{children:["Token Weighting: ",(0,s.jsx)(i.code,{children:"Prompt Emphasis"})]}),id:"token-weighting-prompt-emphasis",depth:3},{value:(0,s.jsx)(s.Fragment,{children:(0,s.jsx)(i.code,{children:"lora"})}),id:"lora",depth:3},{value:"Prompting in vision / video aspects",id:"prompting-in-vision--video-aspects",depth:2},{value:"1. Providing camera aspects",id:"1-providing-camera-aspects",depth:3},{value:"1. Camera starting point",id:"1-camera-starting-point",depth:4},{value:"2. Angles",id:"2-angles",depth:4},{value:"3. Zoom",id:"3-zoom",depth:4},{value:"4. Lens using",id:"4-lens-using",depth:4},{value:"5. Brand",id:"5-brand",depth:4},{value:"6. ISO",id:"6-iso",depth:4},{value:"7. Frame",id:"7-frame",depth:4},{value:"8. Director style",id:"8-director-style",depth:4},{value:"2. Providing environment aspects",id:"2-providing-environment-aspects",depth:3},{value:"1. Place",id:"1-place",depth:4},{value:"2. Weather",id:"2-weather",depth:4},{value:"3. Other objects",id:"3-other-objects",depth:4},{value:"4. Buildings",id:"4-buildings",depth:4},{value:"5. Time background",id:"5-time-background",depth:4},{value:"6. Specific target",id:"6-specific-target",depth:4},{value:"3. Providing objective aspects",id:"3-providing-objective-aspects",depth:3},{value:"1. Your main character",id:"1-your-main-character",depth:4},{value:"2. Styling",id:"2-styling",depth:4},{value:"3. Equipment",id:"3-equipment",depth:4},{value:"4. Face express",id:"4-face-express",depth:4},{value:"5. Hand and legs movement",id:"5-hand-and-legs-movement",depth:4},{value:"6. Eyes sight",id:"6-eyes-sight",depth:4},{value:"7. Feelings",id:"7-feelings",depth:4},{value:"8. Looking at",id:"8-looking-at",depth:4},{value:"3.1 Prompting a character",id:"31-prompting-a-character",depth:3},{value:"1. Gender",id:"1-gender",depth:4},{value:"2. Class",id:"2-class",depth:4},{value:"3. Face",id:"3-face",depth:4},{value:"4. Head / Hair",id:"4-head--hair",depth:4},{value:"5. Wearings",id:"5-wearings",depth:4},{value:"6. Hand / Arms/ Legs position",id:"6-hand--arms-legs-position",depth:4},{value:"7. Pose",id:"7-pose",depth:4},{value:"8. Styles",id:"8-styles",depth:4},{value:"9. References",id:"9-references",depth:4},{value:"4. Providing animations aspects",id:"4-providing-animations-aspects",depth:3},{value:"1. What is moving in the sence?",id:"1-what-is-moving-in-the-sence",depth:4},{value:"2. How the main / sub character moving.",id:"2-how-the-main--sub-character-moving",depth:4},{value:"3. Any happening around the camers?",id:"3-any-happening-around-the-camers",depth:4},{value:"4. Is There Any Transforming Happening?",id:"4-is-there-any-transforming-happening",depth:4},{value:"5. Providing effects aspects (For video)",id:"5-providing-effects-aspects-for-video",depth:3},{value:"1. How the camera behave",id:"1-how-the-camera-behave",depth:4},{value:"2. Following the main character",id:"2-following-the-main-character",depth:4},{value:"3. Fixed camer",id:"3-fixed-camer",depth:4},{value:"4. Zoom in to out?",id:"4-zoom-in-to-out",depth:4},{value:"5. High angle?",id:"5-high-angle",depth:4},{value:"6. Two different cameras?",id:"6-two-different-cameras",depth:4},{value:"Images / Graph promptings \uD83D\uDED5",id:"images--graph-promptings-",depth:2},{value:"Let’s break down the prompts \uD83D\uDE96",id:"lets-break-down-the-prompts-",depth:3},{value:"Images / Graph example \uD83C\uDF04",id:"images--graph-example-",depth:2},{value:"Let’s break down the prompts \uD83C\uDF04",id:"lets-break-down-the-prompts--1",depth:3},{value:"Extra",id:"extra",depth:2},{value:"GPT to video / image prompt",id:"gpt-to-video--image-prompt",depth:3},{value:"CLIP Interrogator",id:"clip-interrogator",depth:3},{value:"Stable Diffusion web UI",id:"stable-diffusion-web-ui",depth:3},{value:"Try more applications",id:"try-more-applications",depth:3}]}var a=(0,r.c)(function(e){let{toc:i=c(e)}=e,n={a:"a",blockquote:"blockquote",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",ul:"ul",...(0,l.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{children:"Techniques for Graphics Generation"}),"\n",(0,s.jsx)(n.p,{children:"Students through Innovative Techniques for Graphics Generation"}),"\n",(0,s.jsx)(n.p,{children:"Lecture 2 - Advance prompting in computer vision & video"}),"\n",(0,s.jsx)(n.h2,{id:i[0].id,children:i[0].value}),"\n",(0,s.jsx)(n.p,{children:"The fundamental concepts of how your prompts will be translated into images."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"GAN utilizes multiplicative integration that allows flexible region-based modulation, and can thus be seen as a generalization of the successful StyleGAN network."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/dorarad/gansformer",children:"https://github.com/dorarad/gansformer"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:720/format:webp/1*2KczvC4RsNyF6P01nYMlPw.png",alt:"bg w:100%"})}),"\n",(0,s.jsx)(n.h3,{id:i[1].id,children:i[1].value}),"\n",(0,s.jsx)(n.p,{children:"Several key words that you have to know:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Noise"}),": A math generated ",(0,s.jsx)(n.code,{children:"random"})," noice images."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Generator (CNN)"})," : Generate images by input ",(0,s.jsx)(n.code,{children:"Noise"}),", and output the ",(0,s.jsx)(n.code,{children:"images"}),"\n",(0,s.jsx)(n.code,{children:"Convolutional neural network (CNN)"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Discriminator (DNN)"}),": Try to identify ",(0,s.jsx)(n.code,{children:"Generator"})," images whether it s similar to the real image.\n",(0,s.jsx)(n.code,{children:"Deconvolutional Neural Network (DNN)"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://cdn.ttgtmedia.com/rms/onlineimages/structure_of_a_gan-f.png",alt:"bg w:100%"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://www.researchgate.net/publication/326012274/figure/fig9/AS:960478171910172@1606007249360/Deconvolution-network-architecture.png",alt:"bg w:100%"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://www.xenonstack.com/hubfs/generative-adversarial-networks.png",alt:"bg w:100%"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://www.microsoft.com/en-us/research/uploads/prodnew/2021/04/Figure-8_GAN-blog_high-res-1024x384.jpg",alt:"bg w:100%"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"w:90%",placeholder:"blur",src:o})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["StackGAN: Text to Photo-realistic ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/1612.03242",children:"https://arxiv.org/pdf/1612.03242"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"In the early stages, the generated image will appear as noise"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://www.microsoft.com/en-us/research/uploads/prodnew/2021/04/Figure6_GanBlog_high-res-1024x542.jpg",alt:"h:500"})}),"\n",(0,s.jsx)(n.h3,{id:i[2].id,children:i[2].value}),"\n",(0,s.jsx)(n.p,{children:"In brief, the GAN process reconstructs noise into meaningful images using deep learning methods."}),"\n",(0,s.jsx)(n.p,{children:"e.g."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"Convolutions Networking (CNN and DNN)"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"Transformer in vision (VIT)"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"Feed forward Dense"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:i[3].id,children:i[3].value}),"\n",(0,s.jsxs)(n.p,{children:["SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis\nA latent diffusion model for text-to-image synthesis. Which implemented text-encoder to allow models to generate text related ",(0,s.jsx)(n.code,{children:"noise"})," for reconstruct prompt related images."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"SD"}),": Stable Diffusion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"SDXL"}),": Stable Diffusion XL"]}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2307.01952",children:"https://arxiv.org/pdf/2307.01952"})}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://d1dwq032kyr03c.cloudfront.net/upload/images/20231007/20162522osR0V2lMLW.jpg",alt:"bg w:100%"})}),"\n",(0,s.jsx)(n.h2,{id:i[4].id,children:i[4].value}),"\n",(0,s.jsxs)("div",{class:"columns",children:[(0,s.jsxs)("div",{children:[(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"lower-dimensional space that captures the essential features of the input data."}),"\n"]}),(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"QKV"})," structure, the latent space of the visual aspect refers to specific features or characteristics, somewhat similar to the ",(0,s.jsx)(n.code,{children:"PCA"})," method."]}),(0,s.jsx)(n.p,{children:"You can establish the relationship between text and images through various aspects such as color, location, object, action, and more."})]}),(0,s.jsx)("div",{children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://www.baeldung.com/wp-content/uploads/sites/4/2022/03/image_latent_space-1024x589.png",alt:"w:500"})})})]}),"\n",(0,s.jsx)(n.h2,{id:i[5].id,children:i[5].value}),"\n",(0,s.jsxs)("div",{class:"columns",children:[(0,s.jsxs)("div",{children:[(0,s.jsx)(n.h3,{id:i[6].id,children:i[6].value}),(0,s.jsx)(n.p,{children:"Conceptual visualization of a block of our modified multimodal diffusion transformer: MMDiT"}),(0,s.jsxs)(n.p,{children:["which employs your input text for ",(0,s.jsx)(n.code,{children:"QKV"})," learning in the transformer to understand the relationship features between ",(0,s.jsx)(n.code,{children:"images"})," and ",(0,s.jsx)(n.code,{children:"text"}),"."]})]}),(0,s.jsx)("div",{children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://images.prismic.io/encord/Zeb7ZeXgT-BdbvKK_image17.png?auto=format,compress",alt:"w:100%"})})})]}),"\n",(0,s.jsx)(n.h3,{id:i[7].id,children:i[7].value}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:720/format:webp/1*MIN6ugtDS5Sfzc1JWTKS_g.png",alt:"w:1200"})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2312.14385",children:"https://arxiv.org/pdf/2312.14385"})}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Your ",(0,s.jsx)(n.code,{children:"prompt"})," will be processed with a ",(0,s.jsx)(n.code,{children:"text-encoder"})," to generate ",(0,s.jsx)(n.code,{children:"noise images"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.code,{children:"noise"})," image will be reconstructed into real images using the SD models multiple times with a ",(0,s.jsx)(n.code,{children:"Denoising U-Net"}),", which consists of an ",(0,s.jsx)(n.code,{children:"encoder"})," and ",(0,s.jsx)(n.code,{children:"decoder"})," network similar to ",(0,s.jsx)(n.code,{children:"GAN"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.code,{children:"Latent Space"})," stores all the text and image features, helping the models generate relevant ",(0,s.jsx)(n.code,{children:"noise"})," based on input prompts."]}),"\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.code,{children:"SD models"})," are pretrained on numerous labeled images with prompts, enabling them to understand the relationship between text and image noise features."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:i[8].id,children:i[8].value}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Learn how Stable Diffusion transformsyour text prompt into image\n",(0,s.jsx)(n.a,{href:"https://poloclub.github.io/diffusion-explainer/",children:"https://poloclub.github.io/diffusion-explainer/"}),"\n",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2305.03509",children:"https://arxiv.org/pdf/2305.03509"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["How does Stable Diffusion work?\n",(0,s.jsx)(n.a,{href:"https://stable-diffusion-art.com/how-stable-diffusion-work/",children:"https://stable-diffusion-art.com/how-stable-diffusion-work/"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:i[9].id,children:i[9].value}),"\n",(0,s.jsxs)(n.p,{children:["Understanding these fundamental terms will help you grasp the basics of ",(0,s.jsx)(n.code,{children:"text-to-media"}),", even though some syntax or tools may become deprecated or unsuitable for your final assignment with selected tools."]}),"\n",(0,s.jsx)(n.h3,{id:i[10].id,children:i[10].value}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"CFG scale (guidance scale)"}),":",(0,s.jsx)(n.br,{}),"\n","Means ",(0,s.jsx)(n.code,{children:"Temperacture"}),", higher value means to more precise to your prompt.\n(You can imagine it to “creativity” control)"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Sampler"}),":",(0,s.jsx)(n.br,{}),"\n","The ",(0,s.jsx)(n.code,{children:"method"})," to generate the ",(0,s.jsx)(n.code,{children:"noise"})," image. Refer to your selected models."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Steps (Epoch)"}),":",(0,s.jsx)(n.br,{}),"\n","How many steps will the generate process to the ",(0,s.jsx)(n.code,{children:"noise"})," image, please refer to ",(0,s.jsx)(n.code,{children:"page 10"})," epoch."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Seed"}),":",(0,s.jsx)(n.br,{}),"\n","The random fixed number for you to obtain the same result."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"CLIP Skip"}),":",(0,s.jsx)(n.br,{}),"\n","Constative Language-Image Pre-training, used to transfer your prompt into noise vector.\n",(0,s.jsx)(n.code,{children:"CLIP Skip"})," provides the possibility to skip several ",(0,s.jsx)(n.code,{children:"text-encoding"})," layers, to prevent ",(0,s.jsx)(n.code,{children:"overfitting"})," in ",(0,s.jsx)(n.code,{children:"SD"}),".\n(AKA: How accurate you want the text model to be)"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Prompt"}),":",(0,s.jsx)(n.br,{}),"\n","Your input prompt, to generate the desire images / video"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Negative Prompt"}),":",(0,s.jsx)(n.br,{}),"\n","Your input negative prompt, to prevent the model to generate these unwanted items. (e.g. Bad hands, NSFW, two heads…)"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Embaddings"}),":",(0,s.jsx)(n.br,{}),"\n","A preset of ",(0,s.jsx)(n.code,{children:"Prompt"}),", means a scripted text embaddings for specific prompt text. Can be scripted to ",(0,s.jsx)(n.code,{children:"Negative prompt"})," or ",(0,s.jsx)(n.code,{children:"Positive prompt"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:i[11].id,children:i[11].value}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Increases attention: ",(0,s.jsx)(n.code,{children:"( )"})," , ",(0,s.jsx)(n.code,{children:"(( ))"}),", ",(0,s.jsx)(n.code,{children:"(token:n.n)"})]}),"\n",(0,s.jsxs)(n.li,{children:["Decreases attention: ",(0,s.jsx)(n.code,{children:"[]"}),", ",(0,s.jsx)(n.code,{children:"[[ ]]"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Which helps to scale the affect power the target prompt text."}),"\n",(0,s.jsxs)(n.p,{children:["e.g. ",(0,s.jsx)(n.code,{children:"boy, (big head: 1.5), sunny day"}),"\nThe affect of ",(0,s.jsx)(n.code,{children:"big head"})," will be scale to 1.5 in this prompt."]}),"\n",(0,s.jsx)(n.h3,{id:i[12].id,children:i[12].value}),"\n",(0,s.jsx)(n.p,{children:"Low-Rank Adaptation (LoRA) is a technique used to add parameters and incorporate unseen fine-tuning data into existing models."}),"\n",(0,s.jsx)(n.p,{children:"LORA Applications:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Allow an ",(0,s.jsx)(n.code,{children:"SD model"})," to generate an unseen character (e.g., Eren Yeager)."]}),"\n",(0,s.jsxs)(n.li,{children:["Add various ",(0,s.jsx)(n.code,{children:"styles"})," to generated models (e.g., hand drawings, cartoon style)."]}),"\n",(0,s.jsxs)(n.li,{children:["Enhance models by adding ",(0,s.jsx)(n.code,{children:"details"})," or making ",(0,s.jsx)(n.code,{children:"adjustments"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:i[13].id,children:i[13].value}),"\n",(0,s.jsx)(n.p,{children:"Here are 5 points of prompting to vision aspects."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"camera"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"environment"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"objective"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"animations"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"effects"})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Which can be intergrated into ",(0,s.jsx)(n.code,{children:"style"})," / ",(0,s.jsx)(n.code,{children:"medium"})," / ",(0,s.jsx)(n.code,{children:"color & lighting"})," / ",(0,s.jsx)(n.code,{children:"composition"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"!! Those are just suggested aspects, not a strict rule. !!"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:i[14].id,children:i[14].value}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Camera starting point"}),"\n",(0,s.jsx)(n.li,{children:"Angles"}),"\n",(0,s.jsx)(n.li,{children:"Zoom"}),"\n",(0,s.jsx)(n.li,{children:"Lens using"}),"\n",(0,s.jsx)(n.li,{children:"Brand"}),"\n",(0,s.jsx)(n.li,{children:"ISO"}),"\n",(0,s.jsx)(n.li,{children:"Frame"}),"\n",(0,s.jsx)(n.li,{children:"Director style"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:i[15].id,children:i[15].value}),"\n",(0,s.jsx)(n.p,{children:"low to the ground, upward angle, eye level"}),"\n",(0,s.jsx)(n.h4,{id:i[16].id,children:i[16].value}),"\n",(0,s.jsx)(n.p,{children:"dynamic angles, wide overhead shot, intimate close-up, 45-degree angle"}),"\n",(0,s.jsx)(n.h4,{id:i[17].id,children:i[17].value}),"\n",(0,s.jsx)(n.p,{children:"slow zoom-in, tightening focus, subtle emotions"}),"\n",(0,s.jsx)(n.h4,{id:i[18].id,children:i[18].value}),"\n",(0,s.jsx)(n.p,{children:"wide-angle lens, expansive landscape, close foreground action"}),"\n",(0,s.jsx)(n.h4,{id:i[19].id,children:i[19].value}),"\n",(0,s.jsx)(n.p,{children:"Canon EOS R5, crispness, dynamic range, shadow and light details"}),"\n",(0,s.jsx)(n.h4,{id:i[20].id,children:i[20].value}),"\n",(0,s.jsx)(n.p,{children:"low light, ISO 3200, moody, atmospheric, grain, noise"}),"\n",(0,s.jsx)(n.h4,{id:i[21].id,children:i[21].value}),"\n",(0,s.jsx)(n.p,{children:"rule of thirds, balanced, visually appealing"}),"\n",(0,s.jsx)(n.h4,{id:i[22].id,children:i[22].value}),"\n",(0,s.jsx)(n.p,{children:"Quentin Tarantino, long takes, steady camera movements, quick cuts, tension, urgency"}),"\n",(0,s.jsx)(n.h3,{id:i[23].id,children:i[23].value}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Place"}),"\n",(0,s.jsx)(n.li,{children:"Weather"}),"\n",(0,s.jsx)(n.li,{children:"Other objects"}),"\n",(0,s.jsx)(n.li,{children:"Buildings"}),"\n",(0,s.jsx)(n.li,{children:"Time background"}),"\n",(0,s.jsx)(n.li,{children:"Specific target"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:i[24].id,children:i[24].value}),"\n",(0,s.jsx)(n.p,{children:"urban setting, forest, beach, mountaintop"}),"\n",(0,s.jsx)(n.h4,{id:i[25].id,children:i[25].value}),"\n",(0,s.jsx)(n.p,{children:"overcast, rainy, sunny, foggy, stormy"}),"\n",(0,s.jsx)(n.h4,{id:i[26].id,children:i[26].value}),"\n",(0,s.jsx)(n.p,{children:"vehicles, trees, animals, furniture, props"}),"\n",(0,s.jsx)(n.h4,{id:i[27].id,children:i[27].value}),"\n",(0,s.jsx)(n.p,{children:"skyscrapers, cottages, warehouses, historic landmarks"}),"\n",(0,s.jsx)(n.h4,{id:i[28].id,children:i[28].value}),"\n",(0,s.jsx)(n.p,{children:"dusk, dawn, midday, midnight, golden hour"}),"\n",(0,s.jsx)(n.h4,{id:i[29].id,children:i[29].value}),"\n",(0,s.jsx)(n.p,{children:"protagonist, vehicle, object, landscape, crowd"}),"\n",(0,s.jsx)(n.h3,{id:i[30].id,children:i[30].value}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Your main character"}),"\n",(0,s.jsx)(n.li,{children:"Styling"}),"\n",(0,s.jsx)(n.li,{children:"Equipment"}),"\n",(0,s.jsx)(n.li,{children:"Face express"}),"\n",(0,s.jsx)(n.li,{children:"Hand and legs movement"}),"\n",(0,s.jsx)(n.li,{children:"Eyes sight"}),"\n",(0,s.jsx)(n.li,{children:"Feelings"}),"\n",(0,s.jsx)(n.li,{children:"Looking at"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:i[31].id,children:i[31].value}),"\n",(0,s.jsx)(n.p,{children:"hero, villain, child, elder, stranger, boy"}),"\n",(0,s.jsx)(n.h4,{id:i[32].id,children:i[32].value}),"\n",(0,s.jsx)(n.p,{children:"casual, formal, rugged, vintage, futuristic"}),"\n",(0,s.jsx)(n.h4,{id:i[33].id,children:i[33].value}),"\n",(0,s.jsx)(n.p,{children:"weapon, tool, accessory, gadget, prop"}),"\n",(0,s.jsx)(n.h4,{id:i[34].id,children:i[34].value}),"\n",(0,s.jsx)(n.p,{children:"smile, frown, grimace, surprise, determination"}),"\n",(0,s.jsx)(n.h4,{id:i[35].id,children:i[35].value}),"\n",(0,s.jsx)(n.p,{children:"slow walk, sprint, gesture, fidget, stance"}),"\n",(0,s.jsx)(n.h4,{id:i[36].id,children:i[36].value}),"\n",(0,s.jsx)(n.p,{children:"direct gaze, side glance, downward look, scanning, focused"}),"\n",(0,s.jsx)(n.h4,{id:i[37].id,children:i[37].value}),"\n",(0,s.jsx)(n.p,{children:"joy, fear, anger, sadness, confusion"}),"\n",(0,s.jsx)(n.h4,{id:i[38].id,children:i[38].value}),"\n",(0,s.jsx)(n.p,{children:"another character, distant object, mirror, camera, horizon"}),"\n",(0,s.jsx)(n.h3,{id:i[39].id,children:i[39].value}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Gender (Boy / Girl / Others)"}),"\n",(0,s.jsx)(n.li,{children:"Class"}),"\n",(0,s.jsx)(n.li,{children:"Face"}),"\n",(0,s.jsx)(n.li,{children:"Head / Hair"}),"\n",(0,s.jsx)(n.li,{children:"Wearings"}),"\n",(0,s.jsx)(n.li,{children:"Hand / Arms/ Legs position"}),"\n",(0,s.jsx)(n.li,{children:"Pose"}),"\n",(0,s.jsx)(n.li,{children:"Styles"}),"\n",(0,s.jsx)(n.li,{children:"References"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:i[40].id,children:i[40].value}),"\n",(0,s.jsx)(n.p,{children:"boy, girl, non-binary, androgynous"}),"\n",(0,s.jsx)(n.h4,{id:i[41].id,children:i[41].value}),"\n",(0,s.jsx)(n.p,{children:"upper class, middle class, working class, royalty, street"}),"\n",(0,s.jsx)(n.h4,{id:i[42].id,children:i[42].value}),"\n",(0,s.jsx)(n.p,{children:"sharp features, soft features, round face, angular, expressive"}),"\n",(0,s.jsx)(n.h4,{id:i[43].id,children:i[43].value}),"\n",(0,s.jsx)(n.p,{children:"short hair, long hair, messy, styled, hat, headpiece"}),"\n",(0,s.jsx)(n.h4,{id:i[44].id,children:i[44].value}),"\n",(0,s.jsx)(n.p,{children:"suit, dress, casual clothes, uniform, accessories"}),"\n",(0,s.jsx)(n.h4,{id:i[45].id,children:i[45].value}),"\n",(0,s.jsx)(n.p,{children:"crossed arms, hands in pockets, outstretched arms, standing, sitting, bent knees"}),"\n",(0,s.jsx)(n.h4,{id:i[46].id,children:i[46].value}),"\n",(0,s.jsx)(n.p,{children:"confident, relaxed, tense, dynamic, casual"}),"\n",(0,s.jsx)(n.h4,{id:i[47].id,children:i[47].value}),"\n",(0,s.jsx)(n.p,{children:"modern, vintage, futuristic, bohemian, minimalist, Japanese comics, Pixar Animation, Kyoto Animation, Lascaux"}),"\n",(0,s.jsx)(n.h4,{id:i[48].id,children:i[48].value}),"\n",(0,s.jsx)(n.p,{children:"fashion magazines, movie characters, historical figures, cultural icons, art styles"}),"\n",(0,s.jsx)(n.h3,{id:i[49].id,children:i[49].value}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"What is moving in the sence?"}),"\n",(0,s.jsx)(n.li,{children:"How the main / sub character moving."}),"\n",(0,s.jsx)(n.li,{children:"Any stars / magic / fog / object happening around the camers?"}),"\n",(0,s.jsx)(n.li,{children:"Is there any transforming happens?"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:i[50].id,children:i[50].value}),"\n",(0,s.jsx)(n.p,{children:"vehicle, leaves, water, animals, shadows"}),"\n",(0,s.jsx)(n.h4,{id:i[51].id,children:i[51].value}),"\n",(0,s.jsx)(n.p,{children:"walking, running, floating, dancing, crawling"}),"\n",(0,s.jsx)(n.h4,{id:i[52].id,children:i[52].value}),"\n",(0,s.jsx)(n.p,{children:"sparkles, mist, fireflies, glowing light, floating debris"}),"\n",(0,s.jsx)(n.h4,{id:i[53].id,children:i[53].value}),"\n",(0,s.jsx)(n.p,{children:"shape-shifting, morphing, growing, shrinking, merging"}),"\n",(0,s.jsx)(n.h3,{id:i[54].id,children:i[54].value}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"How the camera behave?"}),"\n",(0,s.jsx)(n.li,{children:"Following the main character?"}),"\n",(0,s.jsx)(n.li,{children:"Fixed camer?"}),"\n",(0,s.jsx)(n.li,{children:"Zoom in to out?"}),"\n",(0,s.jsx)(n.li,{children:"High angle?"}),"\n",(0,s.jsx)(n.li,{children:"Two different cameras?"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:i[55].id,children:i[55].value}),"\n",(0,s.jsx)(n.p,{children:"panning, tracking, tilting, steady, handheld"}),"\n",(0,s.jsx)(n.h4,{id:i[56].id,children:i[56].value}),"\n",(0,s.jsx)(n.p,{children:"tracking shot, over-the-shoulder, side-by-side, circling"}),"\n",(0,s.jsx)(n.h4,{id:i[57].id,children:i[57].value}),"\n",(0,s.jsx)(n.p,{children:"stationary, locked-off, tripod-mounted, stable frame"}),"\n",(0,s.jsx)(n.h4,{id:i[58].id,children:i[58].value}),"\n",(0,s.jsx)(n.p,{children:"dolly zoom, gradual zoom out, fast zoom in, reverse zoom"}),"\n",(0,s.jsx)(n.h4,{id:i[59].id,children:i[59].value}),"\n",(0,s.jsx)(n.p,{children:"bird’s-eye view, top-down shot, overhead, downward angle"}),"\n",(0,s.jsx)(n.h4,{id:i[60].id,children:i[60].value}),"\n",(0,s.jsx)(n.p,{children:"dual perspective, split-screen, cross-cutting, alternating angle"}),"\n",(0,s.jsx)(n.h2,{id:i[61].id,children:i[61].value}),"\n",(0,s.jsx)(n.p,{children:"Guess what prompt text is used?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"White Moon?"}),"\n",(0,s.jsx)(n.li,{children:"Girl holding lantern and sword?"}),"\n",(0,s.jsx)(n.li,{children:"Night street in USA?"}),"\n",(0,s.jsx)(n.li,{children:"Walking to a huge giant?"}),"\n",(0,s.jsx)(n.li,{children:"Green light?"}),"\n",(0,s.jsx)(n.li,{children:"Camera center?"}),"\n",(0,s.jsx)(n.li,{children:"Slowly towards?"}),"\n",(0,s.jsx)(n.li,{children:"And more?"}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["Ref: ",(0,s.jsx)(n.a,{href:"https://civitai.com/images/22874510",children:"https://civitai.com/images/22874510"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"w:500 bg right:33%",placeholder:"blur",src:d})}),"\n",(0,s.jsx)(n.p,{children:"Atmospheric slow-motion video of a desolate cityscape, capturing the girl with a backpack,\nmagic green lantern, and toy sword.\nThe camera pans from a darkened street toward the haunting silhouette of Slenderman on the horizon.\nDim moonlight filters through clouds,\nenhancing a chilling, suspenseful ambiance, evoking fear and wonder."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"w:500 bg right:33%",placeholder:"blur",src:d})}),"\n",(0,s.jsx)(n.h3,{id:i[62].id,children:i[62].value}),"\n",(0,s.jsx)(n.p,{children:"Camera motion:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Atmospheric slow-motion video of a desolate cityscape"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Camera Actions:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"capturing the girl with a backpack, magic green lantern, and toy sword."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Object features:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"girl with a backpack, magic green lantern, and toy sword."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Atmosphere and camera motion describe:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The camera pans from a darkened street toward the haunting silhouette of Slenderman on the horizon."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Setting background and place describe:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Dim moonlight filters through clouds, enhancing a chilling, suspenseful ambiance, evoking fear and wonder."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Just for the reference to this text-to-video, you may adjust or remove the necessary parts in order to fullfill your requirement."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://lumaai.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F14931503-c633-4879-a790-4e40eb4d9429%2F9d243a5d-bd30-42a9-9d8b-183e0b02e683%2FQY_N-dNp.jpg?table=block&id=c26a15fe-fa20-4e1c-8139-430f62d4b4aa&spaceId=14931503-c633-4879-a790-4e40eb4d9429&width=2000&userId=&cache=v2",alt:"bg"})}),"\n",(0,s.jsx)(n.h2,{id:i[63].id,children:i[63].value}),"\n",(0,s.jsx)(n.p,{children:"-movie stills of bladerunner 2049, skyscrapers advertisements on buildings tv, sci-fi film, Dynamic pose, photograph taken by Michael Bay on a CANON EOS C500 MARK II, f/22, Shutter Speed 1/ 1000, ISO 1000, 55mm lens, low lighting, cinematic scene, fx, HDR, epic composition, cinematic photo, hyper - realistic, hyper - detailed, cinematic lighting, particle effects, action photography, hyper realistic, 8k resolution, unreal engine, photorealistic masterpiece, smooth, real photography, full hd, Megapixel, Pro Photo RGB, VR, Good, Massive, Half rear Lighting, Backlight, Incandescent, Optical Fiber, Moody Lighting, Studio Lighting, Soft Lighting, Volumetric, Conte - Jour, Beautiful Lighting, Accent Lighting, Screen, Ray Tracing Global Illumination, Optics, Scattering, Glowing, Shadows, Rough, Shimmering, Ray Tracing Reflections, Lumen Reflections, Screen Space Reflections, Diffraction Grading, Chromatic Aberration, GB Displacement, Scan Lines, Ray Traced, Ray Tracing Ambient Occlusi on, Anti - Aliasing, FKAA, TXAA, RTX, SSAO, Shaders, OpenGL - Shaders, GLSL - Shaders, Post Processing…"}),"\n",(0,s.jsx)(n.h3,{id:i[64].id,children:i[64].value}),"\n",(0,s.jsx)(n.p,{children:"Camera style:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"photograph taken by Michael Bay on a CANON EOS C500 MARK II, f/22, Shutter Speed 1/ 1000, ISO 1000, 55mm lens, low lighting, cinematic scene, fx, HDR, epic composition, cinematic photo, hyper - realistic, hyper - detailed, cinematic lighting, particle effects, action photography, hyper realistic, 8k resolution, unreal engine, photorealistic masterpiece, smooth, real photography, full hd, Megapixel, Pro Photo RGB, VR, Good, Massive"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Atmosphere:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"movie stills of bladerunner 2049, skyscrapers advertisements on buildings"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Light describe:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Beautiful Lighting, Accent Lighting, Screen, Ray Tracing Global Illumination, Optics, Scattering, Glowing, Shadows, Rough, Shimmering, Ray Tracing Reflections, Lumen Reflections, Screen Space Reflections, Diffraction Grading, Chromatic Aberration, GB Displacement, Scan Lines, Ray Traced, Ray Tracing Ambient Occlusi"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Process describe:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Anti - Aliasing, FKAA, TXAA, RTX, SSAO, Shaders, OpenGL - Shaders, GLSL - Shaders, Post Processing, Post - Production, Cell Shading, Tone Mapping, CGI, VFX, SFX"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["These ",(0,s.jsx)(n.code,{children:"text-to-media"})," structure is just a recommended format, does not mean you have to strictly follow these rules and method. Sometime, let the models create their own style are also a good references."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Try to view more creations from other to see how to construct the wordings."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:i[65].id,children:i[65].value}),"\n",(0,s.jsx)(n.h3,{id:i[66].id,children:i[66].value}),"\n",(0,s.jsx)(n.p,{children:"Q. Can I tell GPT to generate video / images prompt?\nA. Yes, you can turn a systme prompt to tell the GPT for it."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["SDPromptGenerator\n",(0,s.jsx)(n.a,{href:"https://github.com/techvishnu/SDPromptGenerator",children:"https://github.com/techvishnu/SDPromptGenerator"})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:i[67].id,children:i[67].value}),"\n",(0,s.jsxs)(n.p,{children:["Q. Can I reverse the prompt text form images?\nA. Yes, the technology of ",(0,s.jsx)(n.code,{children:"CLIP Interrogator"})," can reverse the image-to-prompt."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Demo:\n",(0,s.jsx)(n.a,{href:"https://huggingface.co/spaces/pharmapsychotic/CLIP-Interrogator",children:"https://huggingface.co/spaces/pharmapsychotic/CLIP-Interrogator"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Interesting paper (Image Captioners Sometimes Tell More Than Images They See)\n",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2305.02932",children:"https://arxiv.org/pdf/2305.02932"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:i[68].id,children:i[68].value}),"\n",(0,s.jsx)(n.p,{children:"Q. Can I self-host the Stable Diffusion models by my own?\nA. Yes, you can create / modify / host your own text-to-images / text-to-video with proper software."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["AUTOMATIC1111 SD webui\n",(0,s.jsx)(n.a,{href:"https://github.com/AUTOMATIC1111/stable-diffusion-webui",children:"https://github.com/AUTOMATIC1111/stable-diffusion-webui"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["ComfyUI\n",(0,s.jsx)(n.a,{href:"https://github.com/comfyanonymous/ComfyUI",children:"https://github.com/comfyanonymous/ComfyUI"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:i[69].id,children:i[69].value}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["viggle\n",(0,s.jsx)(n.a,{href:"https://viggle.ai/home",children:"https://viggle.ai/home"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["tripo3d\n",(0,s.jsx)(n.a,{href:"https://www.tripo3d.ai/",children:"https://www.tripo3d.ai/"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["vidnoz\n",(0,s.jsx)(n.a,{href:"https://www.vidnoz.com/",children:"https://www.vidnoz.com/"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["leonardo\n",(0,s.jsx)(n.a,{href:"https://app.leonardo.ai/",children:"https://app.leonardo.ai/"})]}),"\n"]}),"\n"]})]})},"/genAI/lecture-02/lecture-02",{filePath:"pages/genAI/lecture-02/lecture-02.mdx",timestamp:1735617136e3,pageMap:t.v,frontMatter:{title:"Lecture 2 - Advance prompting in computer vision & video",sidebarTitle:"Lecture 02",description:"Advance prompting in computer vision & video"},title:"Lecture 2 - Advance prompting in computer vision & video"},"undefined"==typeof RemoteContent?c:RemoteContent.useTOC)},3642:function(e,i,n){"use strict";n.d(i,{v:function(){return s}});let s=[{data:{index:{title:"Introduction",type:"page",display:"hidden"},lifeIsPossible:{title:"Life Is Possible Workshop",type:"page"},genAI:{title:"Generative AI",type:"page"}}},{name:"genAI",route:"/genAI",children:[{data:{index:"Intro","lecture-01":"Lecture 1","lecture-02":"Lecture 2"}},{name:"index",route:"/genAI",frontMatter:{title:"Intro - Techniques for Graphics Generation",sidebarTitle:"Intro",description:"Techniques for Graphics Generation introductions"}},{name:"lecture-01",route:"/genAI/lecture-01",children:[{name:"lecture-01",route:"/genAI/lecture-01/lecture-01",frontMatter:{title:"Lecture 1 - Basic prompts for text & code generations",sidebarTitle:"Lecture 01",description:"Basic prompts for text & code generations"}}]},{name:"lecture-02",route:"/genAI/lecture-02",children:[{name:"lecture-02",route:"/genAI/lecture-02/lecture-02",frontMatter:{title:"Lecture 2 - Advance prompting in computer vision & video",sidebarTitle:"Lecture 02",description:"Advance prompting in computer vision & video"}}]}]},{name:"index",route:"/",frontMatter:{sidebarTitle:"Index"}},{name:"lifeIsPossible",route:"/lifeIsPossible",children:[{data:{overall:"Overall","overall-chinese":"Overall (中文)",Lecture:"Lecture"}},{name:"Lecture",route:"/lifeIsPossible/Lecture",children:[{name:"lecture-01",route:"/lifeIsPossible/Lecture/lecture-01",children:[{name:"lecture-01",route:"/lifeIsPossible/Lecture/lecture-01/lecture-01",frontMatter:{title:"Lecture 1 - Introduce to Programming | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 01",description:"Introduce to Programming | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-02",route:"/lifeIsPossible/Lecture/lecture-02",children:[{name:"lecture-02-chinese",route:"/lifeIsPossible/Lecture/lecture-02/lecture-02-chinese",frontMatter:{title:"講課 2 - Introduce to HTML | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 02 Chinese",description:"Introduce to HTML | Life is Possible - 生命教育 手機程式工作坊"}},{name:"lecture-02",route:"/lifeIsPossible/Lecture/lecture-02/lecture-02",frontMatter:{title:"Lecture 2 - Introduce to HTML | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 02",description:"Introduce to HTML | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-03",route:"/lifeIsPossible/Lecture/lecture-03",children:[{name:"lecture-03-chinese",route:"/lifeIsPossible/Lecture/lecture-03/lecture-03-chinese",frontMatter:{title:"Lecture 3 - Introduce to HTML | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 03 Chinese",description:"Introduce to HTML | Life is Possible - 生命教育 手機程式工作坊"}},{name:"lecture-03",route:"/lifeIsPossible/Lecture/lecture-03/lecture-03",frontMatter:{marp:!0,class:"invert",footer:"Life is Possible - Apps workshop",paginate:!0,style:".columns {\n  display: grid;\n  grid-template-columns: repeat(2, minmax(0, 1fr));\n  gap: 1rem;\n}\n\n.columns-three {\n  display: grid;\n  grid-template-columns: repeat(3, minmax(0, 1fr));\n  gap: 1rem;\n}\n",sidebarTitle:"Lecture 03"}}]},{name:"lecture-04",route:"/lifeIsPossible/Lecture/lecture-04",children:[{name:"lecture-04-chinese",route:"/lifeIsPossible/Lecture/lecture-04/lecture-04-chinese",frontMatter:{title:"Lecture 4 - Introduce to JavaScript | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 04 Chinese",description:"Introduce to JavaScript | Life is Possible - 生命教育 手機程式工作坊"}},{name:"lecture-04",route:"/lifeIsPossible/Lecture/lecture-04/lecture-04",frontMatter:{title:"Lecture 4 - Introduce to JavaScript | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 04",description:"Introduce to JavaScript | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-05",route:"/lifeIsPossible/Lecture/lecture-05",children:[{name:"lecture-05-chinese",route:"/lifeIsPossible/Lecture/lecture-05/lecture-05-chinese",frontMatter:{marp:!0,class:"invert",footer:"Life is Possible - Apps workshop",paginate:!0,style:".columns {\n  display: grid;\n  grid-template-columns: repeat(2, minmax(0, 1fr));\n  gap: 1rem;\n}\n",sidebarTitle:"Lecture 05 Chinese"}},{name:"lecture-05",route:"/lifeIsPossible/Lecture/lecture-05/lecture-05",frontMatter:{title:"Lecture 5 - Interact JS in HTML | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 05",description:"Interact JS in HTML | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-06",route:"/lifeIsPossible/Lecture/lecture-06",children:[{name:"lecture-06-chinese",route:"/lifeIsPossible/Lecture/lecture-06/lecture-06-chinese",frontMatter:{title:"Lecture 6 - Adv topic - Github, Deployment and Planning | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 06 Chinese",description:"Adv topic - Github, Deployment and Planning | Life is Possible - 生命教育 手機程式工作坊"}},{name:"lecture-06",route:"/lifeIsPossible/Lecture/lecture-06/lecture-06",frontMatter:{title:"Lecture 6 - Adv topic - Github, Deployment and Planning | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 06",description:"Adv topic - Github, Deployment and Planning | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-07",route:"/lifeIsPossible/Lecture/lecture-07",children:[{name:"lecture-07-chinese",route:"/lifeIsPossible/Lecture/lecture-07/lecture-07-chinese",frontMatter:{title:"講課 7 - Project Week 1 | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 07 Chinese",description:"Project Week 1 | Life is Possible - 生命教育 手機程式工作坊"}},{name:"lecture-07",route:"/lifeIsPossible/Lecture/lecture-07/lecture-07",frontMatter:{title:"Lecture 7 - Project Week 1 | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 07",description:"Project Week 1 | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-08",route:"/lifeIsPossible/Lecture/lecture-08",children:[{name:"lecture-08",route:"/lifeIsPossible/Lecture/lecture-08/lecture-08",frontMatter:{title:"Lecture 8 - Project Week 2 | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 08",description:"Project Week 2 | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-09",route:"/lifeIsPossible/Lecture/lecture-09",children:[{name:"lecture-09",route:"/lifeIsPossible/Lecture/lecture-09/lecture-09",frontMatter:{title:"Lecture 9 - Project Week 3 | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 09",description:"Project Week 3 | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-10",route:"/lifeIsPossible/Lecture/lecture-10",children:[{name:"lecture-10",route:"/lifeIsPossible/Lecture/lecture-10/lecture-10",frontMatter:{title:"Lecture 10 - Showcase | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture 10",description:"Showcase | Life is Possible - 生命教育 手機程式工作坊"}}]},{name:"lecture-ex1",route:"/lifeIsPossible/Lecture/lecture-ex1",children:[{name:"lecture-ex1",route:"/lifeIsPossible/Lecture/lecture-ex1/lecture-ex1",frontMatter:{title:"Lecture ex1 - Advance JS | Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Lecture ex1",description:"Advance JS | Life is Possible - 生命教育 手機程式工作坊"}}]}]},{name:"overall-chinese",route:"/lifeIsPossible/overall-chinese",frontMatter:{title:"介紹 - Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Overall (中文)",description:"Life is Possible - 生命教育 手機程式工作坊 介紹"}},{name:"overall",route:"/lifeIsPossible/overall",frontMatter:{title:"Intro - Life is Possible - 生命教育 手機程式工作坊",sidebarTitle:"Overall",description:"Life is Possible - 生命教育 手機程式工作坊 introductions"}}]}]}},function(e){e.O(0,[486,888,774,179],function(){return e(e.s=3018)}),_N_E=e.O()}]);